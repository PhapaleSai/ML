#.Slip 26A Create KNN model on Indian diabetes patientâ€™s database and predict whether a new 
#patient is diabetic (1) or not (0). Find optimal value of K

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Sample dataset (replace with actual CSV if available)
data = {'Pregnancies':[6,1,8,1,0,5,3,10],
        'Glucose':[148,85,183,89,137,116,78,115],
        'BloodPressure':[72,66,64,66,40,74,50,70],
        'BMI':[33.6,26.6,23.3,28.1,43.1,25.6,31.0,35.3],
        'Age':[50,31,32,21,33,30,26,29],
        'Outcome':[1,0,1,0,1,0,1,0]}
df = pd.DataFrame(data)

X = df.drop('Outcome', axis=1)
y = df['Outcome']

# Split & scale
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Find optimal K
best_k, best_acc = 1,0
for k in range(1,6):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    acc = accuracy_score(y_test, knn.predict(X_test))
    if acc > best_acc:
        best_k, best_acc = k, acc

# Train with optimal K
knn = KNeighborsClassifier(n_neighbors=best_k)
knn.fit(X_train, y_train)
new_patient = [[45, 130, 70, 30.0, 40]]  # Example new patient
new_patient_scaled = scaler.transform(new_patient)
print(f"Optimal K: {best_k}, Prediction (1=Diabetic,0=Not): {knn.predict(new_patient_scaled)[0]}")

-------------------------------------------------------------------------------------------------------------
#SlIP 1A,22B,26B
# Use Apriori algorithm on groceries dataset to find which items are brought together. Use minimum support =0.25 

 # Import necessary libraries
import pandas as pd
from mlxtend.frequent_patterns import apriori, association_rules
# Sample dataset (assuming a structure of one-hot encoded data)
data = {
'milk': [1, 1, 1, 0, 0, 1],
'bread': [1, 0, 1, 1, 1, 0],
'butter': [0, 1, 1, 1, 0, 1],
'beer': [1, 0, 0, 1, 1, 0]
}
df = pd.DataFrame(data)
# Apply Apriori algorithm with minimum support of 0.25
frequent_itemsets = apriori(df, min_support=0.25, use_colnames=True)
# Display results
print("Frequent Itemsets:")
print(frequent_itemsets)
# Generate association rules
rules = association_rules(frequent_itemsets, metric="lift", min_threshold=1)
print("\nAssociation Rules:")
print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])
-------------------------------------------------------------------------------------------------------------
