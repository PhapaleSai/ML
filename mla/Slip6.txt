##SLIP 6A,11A,18B
 ##Write a python program to implement Polynomial Linear Regression for  
##Boston Housing Dataset.(CALIFORNIA DATASET)
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Load dataset
housing = fetch_california_housing()
X, y = housing.data, housing.target

# Polynomial transformation (degree 2)
X_poly = PolynomialFeatures(degree=2).fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=0)

# Train Polynomial Regression model
model = LinearRegression().fit(X_train, y_train)

# Predict and evaluate
y_pred = model.predict(X_test)
print("MSE:", mean_squared_error(y_test, y_pred))
print("R²:", r2_score(y_test, y_pred))
print("First 5 Predicted Prices:", y_pred[:5])
--------------------------------------------------------------------------------------------------------------------------
 ##SLIP 6B,29B
 ##Use K-means clustering model and classify the employees into various income groups 
##or clusters. Preprocess data if require (i.e. drop missing or null values). 

# Import necessary libraries
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

data = {
'Age': [25, 30, 35, 40, 45, 50, 55, 60, 65, 70],
'Years_of_Experience': [1, 3, 5, 8, 10, 12, 15, 20, 22, 25],
'Income': [35000, 40000, 45000, 60000, 70000, 80000, 95000, 120000, 130000, 150000]
}

df = pd.DataFrame(data)

# 2. Check and handle missing values (drop rows with null values in this example)
df = df.dropna()  # Drop missing values

# 3. Feature selection: We will use 'Age', 'Years_of_Experience', and 'Income' as features
X = df[['Age', 'Years_of_Experience', 'Income']]

# 4. Scale the features (important for K-Means)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 5. Apply K-Means clustering (let's choose 3 clusters)
kmeans = KMeans(n_clusters=3, random_state=0)
df['Cluster'] = kmeans.fit_predict(X_scaled)

# 6. Visualize the clusters (optional, for 2D visualization we’ll use Age vs Income)
plt.scatter(df['Age'], df['Income'], c=df['Cluster'], cmap='viridis')
plt.xlabel('Age')
plt.ylabel('Income')
plt.title('Employee Income Clusters')
plt.show()

# Display the data with assigned clusters
print(df)
---------------------------------------------------------------------------------